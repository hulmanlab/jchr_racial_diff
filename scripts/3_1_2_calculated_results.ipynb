{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv(r'/home/hbt/jchr_data/jchr_racial_diff/results/preprocessed_data/1_2_model_input_ws60min_ph60min_v6.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the path to your folder\n",
    "folder_path = '/home/hbt/jchr_data/jchr_racial_diff/results/processed_data/2_1_1_predicted_results_rnn_v6_race'\n",
    "\n",
    "# Pattern to match the files\n",
    "file_pattern = f'{folder_path}/patient*_ratio*.pkl'\n",
    "\n",
    "# Dictionary to store the data\n",
    "dictionary = {}\n",
    "\n",
    "# Iterate over files matched by glob\n",
    "for file_path in glob.glob(file_pattern):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Extracting N and X from the filename\n",
    "        filename = file_path.split('/')[-1]  # Adjust if necessary based on your OS\n",
    "        patient_id, ratio_id = filename.replace('.pkl', '').split('_')\n",
    "        # Extracting numeric parts from patient_id and ratio_id\n",
    "        patient_num = ''.join(filter(str.isdigit, patient_id))\n",
    "        ratio_num = ''.join(filter(str.isdigit, ratio_id))\n",
    "        \n",
    "        # Load the content of the file\n",
    "        file_data = pickle.load(file)\n",
    "\n",
    "        # Store the data\n",
    "        dictionary.update(file_data)\n",
    "\n",
    "# Now loaded_data contains all your files' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 PtID: 179 ratio: 100\n",
      "Iteration: 2 PtID: 127 ratio: 100\n",
      "Iteration: 3 PtID: 45 ratio: 100\n",
      "Iteration: 4 PtID: 120 ratio: 100\n",
      "Iteration: 5 PtID: 133 ratio: 100\n",
      "Iteration: 6 PtID: 202 ratio: 100\n",
      "Iteration: 7 PtID: 88 ratio: 100\n",
      "Iteration: 8 PtID: 139 ratio: 100\n"
     ]
    }
   ],
   "source": [
    "import my_utils\n",
    "iteration = 1\n",
    "dict_results = {}\n",
    "\n",
    "for (PtID, percentage), value in dictionary.items():\n",
    "\n",
    "    print('Iteration:',iteration,'PtID:',PtID,'ratio:' ,percentage)\n",
    "    iteration=iteration+1\n",
    "    \n",
    "    # My actual/true values and my baseline value\n",
    "    y_actual = value['y_actual']\n",
    "    y_last_value = value['y_last_val']\n",
    "    y_pred = value['y_pred']\n",
    "    y_pred_tl = value['y_pred_tl']\n",
    "\n",
    "    # calculating my values for each prediction base_model\n",
    "    rmse_naive = my_utils.calculate_results(y_actual, y_last_value)\n",
    "    rmse_base = my_utils.calculate_results(y_actual, y_pred) \n",
    "    rmse_tl = my_utils.calculate_results(y_actual,y_pred_tl)  \n",
    "    \n",
    "     \n",
    "    dict_results[(PtID, percentage)] = {\n",
    "        \n",
    "        \"group_nr\": value['group_nr'],\n",
    "        \"ptid_group\": value['ptid_group'],\n",
    "        \"rmse_naive\": rmse_naive,\n",
    "        \"rmse_base\": rmse_base,\n",
    "        \"rmse_tl\": rmse_tl,\n",
    "        # \"train\": temp_train_n,\n",
    "        # \"val\": temp_val_n,\n",
    "        # \"train_tl\": temp_train_tl_n,\n",
    "        # \"val_tl\": temp_val_tl_n,\n",
    "        # \"test\": temp_test_n\n",
    "        \n",
    "        \n",
    "        # find number of samples\n",
    "    \n",
    "#     ptid_training_w = value['training_w']\n",
    "#     ptid_training_b = value['training_b']\n",
    "#     ptid_test = value['PtID_test']\n",
    "#     ptid_race = value['race']\n",
    "\n",
    "#     df_train_w = df[df['PtID'].isin(ptid_training_w)]\n",
    "#     df_train_b = df[df['PtID'].isin(ptid_training_b)]\n",
    "#     df_test = df[df['PtID']==ptid_test]\n",
    "    \n",
    "\n",
    "\n",
    "# #                    split dataset using one week of data to validate on the rest\n",
    "\n",
    "#     df_train_wb = pd.concat([df_train_w, df_train_b], ignore_index=True)\n",
    "#     df_train_wb.reset_index\n",
    "\n",
    "#     # split within patients, train/val\n",
    "#     xy_train, xy_val = my_utils.split_within_PtID(df_train_wb, numb_values_to_remove=-672, group_column=\"Race\", seperate_target=False) # split witin  PtID: 4values/hour * 24hour/day*7days/week = 672 values/week\n",
    "\n",
    "#    # split within patients, train/test\n",
    "#     xy_train_tl, xy_test_tl = my_utils.split_within_PtID(df_test, numb_values_to_remove=-672, seperate_target=False, group_column=\"Race\") # split witin  PtID: 4values/hour * 24hour/day*7days/week = 672 values/week\n",
    "\n",
    "#     baseline_test_tl = xy_test_tl['Value_4']\n",
    "\n",
    "#     # split train in train/val with seperate targets\n",
    "#     x_train_tl, y_train_tl, x_val_tl, y_val_tl = my_utils.split_time_series_data(xy_train_tl, test_size=0.15)\n",
    "# #                   getting lengths and saving \n",
    "    \n",
    "\n",
    "    # temp_train_n = (len(xy_train))\n",
    "    # temp_val_n =(len(xy_val))\n",
    "    # temp_train_tl_n=(len(xy_train_tl))\n",
    "    # temp_val_tl_n=(len(x_val_tl))\n",
    "    # temp_test_n=(len(xy_test_tl))\n",
    "\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PtID  ratio group_nr ptid_group  rmse_naive  rmse_base   rmse_tl\n",
      "0   179    100   group1      white    4.795853   1.598607  1.598120\n",
      "1   127    100   group1      white    4.453458   1.869135  1.877093\n",
      "2    45    100   group1      white    4.570325   1.891739  1.842106\n",
      "3   120    100   group2      black    4.326448   1.452027  1.377160\n",
      "4   133    100   group2      black    7.164344   1.991162  1.993682\n",
      "5   202    100   group1      white    6.628821   2.207894  2.244158\n",
      "6    88    100   group1      white    7.243953   2.826020  2.789407\n",
      "7   139    100   group2      black    7.351941   2.361835  2.367197\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(dict_results, orient='index').reset_index()\n",
    "df = df.rename(columns={'level_0': 'PtID', 'level_1': 'ratio'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "# file_path_save = '/home/hbt/jchr_data/jchr_racial_diff/results/processed_data/2_1_1_predicted_results_rnn_wb/2_1_1_predicted_results_rnn_wb_v4/3_1_1_calculated_results_v2.csv'\n",
    "# df.to_csv(file_path_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PtID</th>\n",
       "      <th>ratio</th>\n",
       "      <th>group_nr</th>\n",
       "      <th>ptid_group</th>\n",
       "      <th>rmse_naive</th>\n",
       "      <th>rmse_base</th>\n",
       "      <th>rmse_tl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179</td>\n",
       "      <td>100</td>\n",
       "      <td>group1</td>\n",
       "      <td>white</td>\n",
       "      <td>4.795853</td>\n",
       "      <td>1.598607</td>\n",
       "      <td>1.598120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127</td>\n",
       "      <td>100</td>\n",
       "      <td>group1</td>\n",
       "      <td>white</td>\n",
       "      <td>4.453458</td>\n",
       "      <td>1.869135</td>\n",
       "      <td>1.877093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>group1</td>\n",
       "      <td>white</td>\n",
       "      <td>4.570325</td>\n",
       "      <td>1.891739</td>\n",
       "      <td>1.842106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>group2</td>\n",
       "      <td>black</td>\n",
       "      <td>4.326448</td>\n",
       "      <td>1.452027</td>\n",
       "      <td>1.377160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133</td>\n",
       "      <td>100</td>\n",
       "      <td>group2</td>\n",
       "      <td>black</td>\n",
       "      <td>7.164344</td>\n",
       "      <td>1.991162</td>\n",
       "      <td>1.993682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202</td>\n",
       "      <td>100</td>\n",
       "      <td>group1</td>\n",
       "      <td>white</td>\n",
       "      <td>6.628821</td>\n",
       "      <td>2.207894</td>\n",
       "      <td>2.244158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>88</td>\n",
       "      <td>100</td>\n",
       "      <td>group1</td>\n",
       "      <td>white</td>\n",
       "      <td>7.243953</td>\n",
       "      <td>2.826020</td>\n",
       "      <td>2.789407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>139</td>\n",
       "      <td>100</td>\n",
       "      <td>group2</td>\n",
       "      <td>black</td>\n",
       "      <td>7.351941</td>\n",
       "      <td>2.361835</td>\n",
       "      <td>2.367197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PtID  ratio group_nr ptid_group  rmse_naive  rmse_base   rmse_tl\n",
       "0   179    100   group1      white    4.795853   1.598607  1.598120\n",
       "1   127    100   group1      white    4.453458   1.869135  1.877093\n",
       "2    45    100   group1      white    4.570325   1.891739  1.842106\n",
       "3   120    100   group2      black    4.326448   1.452027  1.377160\n",
       "4   133    100   group2      black    7.164344   1.991162  1.993682\n",
       "5   202    100   group1      white    6.628821   2.207894  2.244158\n",
       "6    88    100   group1      white    7.243953   2.826020  2.789407\n",
       "7   139    100   group2      black    7.351941   2.361835  2.367197"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_study1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
